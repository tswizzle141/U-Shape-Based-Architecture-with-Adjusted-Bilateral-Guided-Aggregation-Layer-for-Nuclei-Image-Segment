{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cell_Segmentation (1).ipynb","provenance":[],"collapsed_sections":["6etAOgpLSdu_","KvDV_mvpTrA6","7Ky_Sm9W90Uk","6Hj2Sf2wcv5k","IBQgiYIcyXvG","NlgBqYz83sqZ","gzAyEyor3Xci","52QrHPPLGPGw","KyJ2U-32eULg","RLddzLS0afYd","QsG4QWY3cchZ","_EQP0AkXi0Gi","tPiu7yXRoGl9"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DIRfer6kwUju"},"source":["# Library"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y1QH4bZamMK","executionInfo":{"status":"ok","timestamp":1654626834521,"user_tz":-420,"elapsed":30932,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}},"outputId":"b1b9a96f-9fe9-4e4c-e0bc-e9967e51f86b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"FVwQ-WlkuVcZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e66af31-ec22-4a09-abfb-c4ef245d978e","executionInfo":{"status":"ok","timestamp":1654626834523,"user_tz":-420,"elapsed":22,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jun  7 18:33:52 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"kOlHCN0Vv8QF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"64eed943-51a6-471d-a52c-0dfad78ff7e8","executionInfo":{"status":"ok","timestamp":1654626842082,"user_tz":-420,"elapsed":7570,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"l6WJQJ9gv_Fl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74c0f623-beba-468b-cd15-c281dd1d1a9f","executionInfo":{"status":"ok","timestamp":1654626860126,"user_tz":-420,"elapsed":18050,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["!pip install import-ipynb\n","!pip install albumentations==0.4.6\n","#!pip install -U efficientnet==0.0.4\n","#!git clone https://github.com/qubvel/efficientnet.git\n","#!pip install -U efficientnet\n","!pip install -U --pre efficientnet\n","!pip install keras-unet-collection"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import-ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.4.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.5.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (0.2.5)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.10.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.15.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (21.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.11.4)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.8.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 32.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Collecting imgaug>=0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 75.4 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.2.0)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=cab4eeca2fe2856f228ef9393329f7771c592d1010d79ac5cce80a94ca760b45\n","  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n","Successfully built albumentations\n","Installing collected packages: imgaug, albumentations\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.4.6 imgaug-0.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting efficientnet\n","  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet) (0.18.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.6)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.5.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.4.1)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.6.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (3.2.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.3.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-unet-collection\n","  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n","\u001b[?25hInstalling collected packages: keras-unet-collection\n","Successfully installed keras-unet-collection-0.1.13\n"]}]},{"cell_type":"code","metadata":{"id":"JEr1WGXswEAd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b999707-8736-459d-8eaf-9ec3427357df","executionInfo":{"status":"ok","timestamp":1654626875541,"user_tz":-420,"elapsed":15427,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["import sys\n","import os\n","import glob\n","from PIL import Image\n","from IPython.display import clear_output\n","import math\n","import random\n","import scipy.io as sio\n","import re\n","import time\n","from tensorflow.keras import models,layers\n","from tensorflow.keras.utils import get_file\n","from collections import namedtuple\n","from tqdm import tqdm, tqdm_notebook\n","from fastprogress.fastprogress import master_bar, progress_bar\n","from time import sleep\n","\n","import numpy as np\n","import pandas as pd\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid import ImageGrid\n","%matplotlib inline\n","import seaborn as sns\n","import zipfile\n","from skimage import io\n","\n","import tensorflow as tf\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras import layers, optimizers\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras.metrics import *\n","import tensorflow.keras.backend as K\n","from sklearn.preprocessing import StandardScaler, normalize\n","from itertools import chain\n","from skimage.io import imread, imshow, imread_collection, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","from tensorflow.keras.utils import Progbar\n","from tensorflow.keras.layers.experimental import preprocessing\n","from IPython.display import display\n","from efficientnet.keras import *\n","from keras_unet_collection import models\n","\n","%cd /content/drive/MyDrive/brain_mri_segmentation/PRANet-Polyps-Segmentation/\n","from model.ra_module import ReverseAttention\n","from model.partial_decoder import PartialDecoder\n","from model.rfb import RFB\n","from model.backbone import FE_backbone\n","\n","%cd /content/drive/MyDrive/MRI_ACDC/\n","from keras_vision_transformer import swin_layers\n","from keras_vision_transformer import transformer_layers\n","from keras_vision_transformer import utils\n","\n","seed = 1234\n","random.seed = seed\n","np.random.seed = seed\n","smooth = 1e-15\n","epochs = 300"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: MatplotlibDeprecationWarning: \n","The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1Dojj8OTWQKrTtjnAqGIo975J73GnTnMb/brain_mri_segmentation/PRANet-Polyps-Segmentation\n","/content/drive/.shortcut-targets-by-id/1JR20ypbQtsjiSTxgEkWdBHUTCTNJfWGR/MRI_ACDC\n"]}]},{"cell_type":"markdown","metadata":{"id":"KQHxRi_CwXPE"},"source":["# Pre-Processing"]},{"cell_type":"code","metadata":{"id":"hMYPecADySBe","executionInfo":{"status":"ok","timestamp":1654626876198,"user_tz":-420,"elapsed":674,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# Data Path\n","TRAIN_PATH = '/content/drive/MyDrive/brain_mri_segmentation/dataset/cell_segmentation/'\n","#TEST_PATH = 'stage1_test/'\n","\n","# Get train and test IDs\n","train_ids = next(os.walk(TRAIN_PATH))[1]\n","#test_ids = next(os.walk(TEST_PATH))[1]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJ242F881MiO","executionInfo":{"status":"ok","timestamp":1654626876199,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def normalize(image,mask):\n","  image = tf.cast(image, tf.float32) / 255.0\n","  mask = tf.cast(mask, tf.float32)\n","  return image,mask"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"G65xpbEMycJX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac2c0962-0fb6-4d6c-ca10-baf80e1c3b8b","executionInfo":{"status":"ok","timestamp":1654626902208,"user_tz":-420,"elapsed":26016,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# Function read train images and mask return as nump array\n","def read_train_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n","    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n","    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","    print('Getting and resizing train images and masks ... ')\n","    sys.stdout.flush()\n","    if os.path.isfile(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/x_train_skin_2018.npy\") and os.path.isfile(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/y_train_skin_2018.npy\"):\n","        print(\"Train file loaded from memory\")\n","        X_train = np.load(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/x_train_skin_2018.npy\")\n","        Y_train = np.load(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/y_train_skin_2018.npy\")\n","        return X_train,Y_train\n","    a = Progbar(len(train_ids))\n","    for n, id_ in enumerate(train_ids):\n","        path = TRAIN_PATH + id_\n","        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n","        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n","        X_train[n] = img\n","        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","        for mask_file in next(os.walk(path + '/masks/'))[2]:\n","            mask_ = imread(path + '/masks/' + mask_file)\n","            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n","                                        preserve_range=True), axis=-1)\n","            mask = np.maximum(mask, mask_)\n","        Y_train[n] = mask\n","        a.update(n)\n","    #np.save(\"/content/drive/MyDrive/brain_mri_segmntateion/dataset/x_train_cell.npy\",X_train)\n","    #np.save(\"/content/drive/MyDrive/brain_mri_segmntateion/dataset/y_train_cell.npy\",Y_train)\n","    return X_train,Y_train\n","\n","# get train_data\n","X_train, Y_train = read_train_data()\n","\n","# get test_data\n","#test_img,test_img_sizes = read_test_data()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Getting and resizing train images and masks ... \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["Train file loaded from memory\n"]}]},{"cell_type":"code","metadata":{"id":"vtxeB3iMK_70","executionInfo":{"status":"ok","timestamp":1654626902208,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["#np.save(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/x_train_cell.npy\", x_train)\n","#np.save(\"/content/drive/MyDrive/brain_mri_segmentation/dataset/y_train_cell.npy\", y_train)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTQio_ly02z-","executionInfo":{"status":"ok","timestamp":1654626966399,"user_tz":-420,"elapsed":6,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["x_train, y_train = normalize(X_train, Y_train)\n","\n","len_dev = X_train.shape[0]//5\n","len_train = X_train.shape[0] - len_dev\n","rand_index = np.random.permutation(X_train.shape[0])\n","x_test = X_train[:len_dev]\n","y_test = Y_train[:len_dev]\n","x_train = X_train[len_dev:]\n","y_train = Y_train[len_dev:]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Y3uJoJtRp-e"},"source":["# Segmentation Training"]},{"cell_type":"markdown","metadata":{"id":"6etAOgpLSdu_"},"source":["## Preparation"]},{"cell_type":"code","metadata":{"id":"SuT2TPVNDL7S","executionInfo":{"status":"aborted","timestamp":1654626798806,"user_tz":-420,"elapsed":42,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def mvn(tensor):\n","    '''Performs per-channel spatial mean-variance normalization.'''\n","    epsilon = 1e-6\n","    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n","    std = K.std(tensor, axis=(1,2), keepdims=True)\n","    mvn = (tensor - mean) / (std + epsilon)\n","    \n","    return mvn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ln7lAgch_So1","executionInfo":{"status":"aborted","timestamp":1654626798808,"user_tz":-420,"elapsed":43,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def crop(tensors):\n","    '''\n","    List of 2 tensors, the second tensor having larger spatial dimensions.\n","    '''\n","    h_dims, w_dims = [], []\n","    for t in tensors:\n","        b, h, w, d = K.int_shape(t)\n","        h_dims.append(h)\n","        w_dims.append(w)\n","    crop_h, crop_w = (h_dims[1] - h_dims[0]), (w_dims[1] - w_dims[0])\n","    rem_h = int(crop_h % 2)\n","    rem_w = int(crop_w % 2)\n","    tt_h = int(crop_h / 2)\n","    tt_w = int(crop_w / 2)\n","    crop_h_dims = (tt_h, tt_h + rem_h)\n","    crop_w_dims = (tt_w, tt_w + rem_w)\n","    cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])\n","    \n","    return cropped"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOa5Wm9K91Es","executionInfo":{"status":"aborted","timestamp":1654626798809,"user_tz":-420,"elapsed":44,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def bn_act(x, act=True):\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    if act == True:\n","        x = tf.keras.layers.Activation(\"relu\")(x)\n","    return x \n","\n","def _conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = bn_act(x)\n","    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n","    return conv \n","\n","def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n","    conv = _conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","\n","    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    shortcut = bn_act(shortcut, act=False)\n","\n","    output = tf.keras.layers.Add()([conv, shortcut])\n","    return output \n","\n","def _residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n","    res = _conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n","    res = _conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n","\n","    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n","    shortcut = bn_act(shortcut, act=False)\n","    \n","    output = tf.keras.layers.Add()([shortcut, res])\n","    return output\n","\n","def upsample_concat_block(x, xskip):\n","    u = tf.keras.layers.UpSampling2D((2, 2))(x)\n","    c = tf.keras.layers.Concatenate()([u, xskip])\n","    return c "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGsJHqIorCsT","executionInfo":{"status":"aborted","timestamp":1654626798811,"user_tz":-420,"elapsed":46,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","\n","    return concate\n","def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","    return concate\n","def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n","    data_format='channels_last'\n","    # theta_x(?,g_height,g_width,inter_channel)\n","\n","    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n","\n","    # phi_g(?,g_height,g_width,inter_channel)\n","\n","    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n","\n","    # f(?,g_height,g_width,inter_channel)\n","\n","    f = Activation('relu')(add([theta_x, phi_g]))\n","\n","    # psi_f(?,g_height,g_width,1)\n","\n","    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n","\n","    rate = Activation('sigmoid')(psi_f)\n","\n","    # rate(?,x_height,x_width)\n","\n","    # att_x(?,x_height,x_width,x_channel)\n","\n","    att_x = multiply([x, rate])\n","\n","    return att_x\n","def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","              padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    layer = input_layer\n","    for i in range(2):\n","        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","        if batch_normalization:\n","            layer = BatchNormalization()(layer)\n","        layer = Activation('relu')(layer)\n","        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n","        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","    out_layer = add([layer, skip_layer])\n","    return out_layer\n","\n","\n","# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n","def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","                  padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","\n","    layer = skip_layer\n","    for j in range(2):\n","\n","        for i in range(2):\n","            if i == 0:\n","\n","                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                    layer)\n","                if batch_normalization:\n","                    layer1 = BatchNormalization()(layer1)\n","                layer1 = Activation('relu')(layer1)\n","            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                add([layer1, layer]))\n","            if batch_normalization:\n","                layer1 = BatchNormalization()(layer1)\n","            layer1 = Activation('relu')(layer1)\n","        layer = layer1\n","\n","    out_layer = add([layer, skip_layer])\n","    return out_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EthkvqmTTYK_","executionInfo":{"status":"aborted","timestamp":1654626798812,"user_tz":-420,"elapsed":46,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    y1 = Lambda(mvn)(y1)\n","    y1 = ReLU()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y2 = Lambda(mvn)(y2)\n","    y2 = ReLU()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y3 = Lambda(mvn)(y3)\n","    y3 = ReLU()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y4 = Lambda(mvn)(y4)\n","    y4 = ReLU()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y5 = Lambda(mvn)(y5)\n","    y5 = ReLU()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    y = Lambda(mvn)(y)\n","    y = ReLU()(y)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0Eh95hIozBw","executionInfo":{"status":"aborted","timestamp":1654626798812,"user_tz":-420,"elapsed":45,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def refinement_module(x, input_filter, middle_filter):\n","  hx = x\n","  hx0 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx)\n","  #print(hx0.shape)\n","\n","  hx1 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx0)\n","  # hx1 = Lambda(mvn)(hx1)\n","  hx1 = BatchNormalization()(hx1)\n","  hx1 = ReLU()(hx1)\n","  hx1 = MaxPooling2D(strides=(2,2))(hx1)\n","  #print(hx1.shape)\n","\n","  hx2 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx1)\n","  # hx2 = Lambda(mvn)(hx2)\n","  hx2 = BatchNormalization()(hx2)\n","  hx2 = ReLU()(hx2)\n","  hx2 = MaxPooling2D(strides=(2,2))(hx2)\n","  #print(hx2.shape)\n","\n","  hx3 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx2)\n","  # hx3 = Lambda(mvn)(hx3)\n","  hx3 = BatchNormalization()(hx3)\n","  hx3 = ReLU()(hx3)\n","  hx3 = MaxPooling2D(strides=(2,2))(hx3)\n","  #print(hx3.shape)\n","\n","  hx4 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx3)\n","  # hx4 = Lambda(mvn)(hx4)\n","  hx4 = BatchNormalization()(hx4)\n","  hx4 = ReLU()(hx4)\n","  hx4 = MaxPooling2D(strides=(2,2))(hx4)\n","  #print(hx4.shape)\n","\n","  hx5 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx4)\n","  # hx5 = Lambda(mvn)(hx5)\n","  hx5 = BatchNormalization()(hx5)\n","  hx5 = ReLU()(hx5)\n","  #print(hx5.shape)\n","  hx5 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx5)\n","  #print(hx5.shape)\n","\n","  hx6 = Concatenate()([hx5, hx3])\n","  hx6 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx6)\n","  # hx6 = Lambda(mvn)(hx6)\n","  hx6 = BatchNormalization()(hx6)\n","  hx6 = ReLU()(hx6)\n","  hx6 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx6)\n","\n","  hx7 = Concatenate()([hx6, hx2])\n","  hx7 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx7)\n","  # hx7 = Lambda(mvn)(hx7)\n","  hx7 = BatchNormalization()(hx7)\n","  hx7 = ReLU()(hx7)\n","  hx7 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx7)\n","\n","  hx8 = Concatenate()([hx7, hx1])\n","  hx6 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx8)\n","  # hx8 = Lambda(mvn)(hx8)\n","  hx8 = BatchNormalization()(hx8)\n","  hx8 = ReLU()(hx8)\n","  hx8 = UpSampling2D(size=(2,2), interpolation='bilinear')(hx8)\n","\n","  hx9 = Concatenate()([hx8, hx0])\n","  hx9 = Conv2D(middle_filter*1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx9)\n","  # hx9 = Lambda(mvn)(hx9)\n","  hx9 = BatchNormalization()(hx9)\n","  hx9 = ReLU()(hx9)\n","  #hx9 = UpSampling2D((hx0.shape[1], hx0.shape[2]), interpolation='bilinear')(hx9)\n","\n","  hx10 = Conv2D(1, 3, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(hx9)\n","  return hx10+x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RGynjxbu1Xb","executionInfo":{"status":"aborted","timestamp":1654626798813,"user_tz":-420,"elapsed":46,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    x = Lambda(mvn)(x) #BatchNormalization()(x)\n","    if activation == True:\n","        x =  ReLU()(x) #LeakyReLU(alpha=0.1)(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16):\n","    x = LeakyReLU(alpha=0.1)(blockInput)\n","    x = BatchNormalization()(x)\n","    blockInput = BatchNormalization()(blockInput)\n","    x = convolution_block(x, num_filters, (3,3))\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    return x\n","\n","def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n","    '''\n","    2D Convolutional layers\n","    \n","    Arguments:\n","        x {keras layer} -- input layer \n","        filters {int} -- number of filters\n","        num_row {int} -- number of rows in filters\n","        num_col {int} -- number of columns in filters\n","    \n","    Keyword Arguments:\n","        padding {str} -- mode of padding (default: {'same'})\n","        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n","        activation {str} -- activation function (default: {'relu'})\n","        name {str} -- name of the layer (default: {None})\n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n","    x = Lambda(mvn)(x) #BatchNormalization(axis=3, scale=False)(x)\n","\n","    if(activation == None):\n","        return x\n","\n","    x = Activation(activation, name=name)(x)\n","\n","    return x\n","\n","def ResPath(filters, length, inp):\n","    '''\n","    ResPath\n","    \n","    Arguments:\n","        filters {int} -- [description]\n","        length {int} -- length of ResPath\n","        inp {keras layer} -- input layer \n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    shortcut = inp\n","    shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n","\n","    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n","\n","    out = add([shortcut, out])\n","    out = Activation('relu')(out)\n","    out = Lambda(mvn)(out) #BatchNormalization(axis=3)(out)\n","\n","    for i in range(length-1):\n","\n","        shortcut = out\n","        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n","\n","        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n","\n","        out = add([shortcut, out])\n","        out = Activation('relu')(out)\n","        out = Lambda(mvn)(out) #BatchNormalization(axis=3)(out)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u75ZBzPrI0-K","executionInfo":{"status":"aborted","timestamp":1654626798814,"user_tz":-420,"elapsed":46,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def _convolution_block(\n","    block_input,\n","    num_filters=256,\n","    kernel_size=3,\n","    dilation_rate=1,\n","    padding=\"same\",\n","    use_bias=False,\n","):\n","    x = layers.Conv2D(\n","        num_filters,\n","        kernel_size=kernel_size,\n","        dilation_rate=dilation_rate,\n","        padding=\"same\",\n","        use_bias=use_bias,\n","        kernel_initializer=tf.keras.initializers.HeNormal(),\n","    )(block_input)\n","    x = layers.BatchNormalization()(x)\n","    return tf.nn.relu(x)\n","\n","\n","def DilatedSpatialPyramidPooling(dspp_input):\n","    dims = dspp_input.shape\n","    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n","    x = _convolution_block(x, kernel_size=1, use_bias=True)\n","    out_pool = layers.UpSampling2D(\n","        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n","    )(x)\n","\n","    out_1 = _convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n","    out_6 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n","    out_12 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n","    out_18 = _convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n","\n","    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n","    output = _convolution_block(x, kernel_size=1)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N3XaNS8uOC75","executionInfo":{"status":"aborted","timestamp":1654626798815,"user_tz":-420,"elapsed":47,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["class BilinearUpsampling(Layer):\n","    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n","       Args:\n","           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n","           output_size: used instead of upsampling arg if passed!\n","    \"\"\"\n","\n","    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n","\n","        super(BilinearUpsampling, self).__init__(**kwargs)\n","\n","        #self.data_format = K.normalize_data_format(data_format)\n","        self.data_format = None\n","        self.input_spec = InputSpec(ndim=4)\n","        if output_size:\n","            self.output_size = conv_utils.normalize_tuple(\n","                output_size, 2, 'output_size')\n","            self.upsampling = None\n","        else:\n","            self.output_size = None\n","            self.upsampling = conv_utils.normalize_tuple(\n","                upsampling, 2, 'upsampling')\n","\n","    def compute_output_shape(self, input_shape):\n","        if self.upsampling:\n","            height = self.upsampling[0] * \\\n","                input_shape[1] if input_shape[1] is not None else None\n","            width = self.upsampling[1] * \\\n","                input_shape[2] if input_shape[2] is not None else None\n","        else:\n","            height = self.output_size[0]\n","            width = self.output_size[1]\n","        return (input_shape[0],\n","                height,\n","                width,\n","                input_shape[3])\n","\n","    def call(self, inputs):\n","        if self.upsampling:\n","            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\n","                                                       inputs.shape[2] * self.upsampling[1]),\n","                                              align_corners=True)\n","        else:\n","            return K.tf.image.resize_bilinear(inputs, (self.output_size[0],\n","                                                       self.output_size[1]),\n","                                              align_corners=True)\n","\n","    def get_config(self):\n","        config = {'upsampling': self.upsampling,\n","                  'output_size': self.output_size,\n","                  'data_format': self.data_format}\n","        base_config = super(BilinearUpsampling, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","\n","def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n","    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n","        Implements right \"same\" padding for even kernel sizes\n","        Args:\n","            x: input tensor\n","            filters: num of filters in pointwise convolution\n","            prefix: prefix before name\n","            stride: stride at depthwise conv\n","            kernel_size: kernel size for depthwise convolution\n","            rate: atrous rate for depthwise convolution\n","            depth_activation: flag to use activation between depthwise & poinwise convs\n","            epsilon: epsilon to use in BN layer\n","    \"\"\"\n","\n","    if stride == 1:\n","        depth_padding = 'same'\n","    else:\n","        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n","        pad_total = kernel_size_effective - 1\n","        pad_beg = pad_total // 2\n","        pad_end = pad_total - pad_beg\n","        x = ZeroPadding2D((pad_beg, pad_end))(x)\n","        depth_padding = 'valid'\n","\n","    if not depth_activation:\n","        x = Activation('relu')(x)\n","    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n","                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n","    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n","    if depth_activation:\n","        x = Activation('relu')(x)\n","    x = Conv2D(filters, (1, 1), padding='same',\n","               use_bias=False, name=prefix + '_pointwise')(x)\n","    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n","    if depth_activation:\n","        x = Activation('relu')(x)\n","\n","    return x\n","\n","\n","def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n","    \"\"\"Implements right 'same' padding for even kernel sizes\n","        Without this there is a 1 pixel drift when stride = 2\n","        Args:\n","            x: input tensor\n","            filters: num of filters in pointwise convolution\n","            prefix: prefix before name\n","            stride: stride at depthwise conv\n","            kernel_size: kernel size for depthwise convolution\n","            rate: atrous rate for depthwise convolution\n","    \"\"\"\n","    if stride == 1:\n","        return Conv2D(filters,\n","                      (kernel_size, kernel_size),\n","                      strides=(stride, stride),\n","                      padding='same', use_bias=False,\n","                      dilation_rate=(rate, rate),\n","                      name=prefix)(x)\n","    else:\n","        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n","        pad_total = kernel_size_effective - 1\n","        pad_beg = pad_total // 2\n","        pad_end = pad_total - pad_beg\n","        x = ZeroPadding2D((pad_beg, pad_end))(x)\n","        return Conv2D(filters,\n","                      (kernel_size, kernel_size),\n","                      strides=(stride, stride),\n","                      padding='valid', use_bias=False,\n","                      dilation_rate=(rate, rate),\n","                      name=prefix)(x)\n","\n","\n","def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n","                    rate=1, depth_activation=False, return_skip=False):\n","    \"\"\" Basic building block of modified Xception network\n","        Args:\n","            inputs: input tensor\n","            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n","            prefix: prefix before name\n","            skip_connection_type: one of {'conv','sum','none'}\n","            stride: stride at last depthwise conv\n","            rate: atrous rate for depthwise convolution\n","            depth_activation: flag to use activation between depthwise & pointwise convs\n","            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n","            \"\"\"\n","    residual = inputs\n","    for i in range(3):\n","        residual = SepConv_BN(residual,\n","                              depth_list[i],\n","                              prefix + '_separable_conv{}'.format(i + 1),\n","                              stride=stride if i == 2 else 1,\n","                              rate=rate,\n","                              depth_activation=depth_activation)\n","        if i == 1:\n","            skip = residual\n","    if skip_connection_type == 'conv':\n","        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n","                                kernel_size=1,\n","                                stride=stride)\n","        shortcut = BatchNormalization(name=prefix + '_shortcut_BN')(shortcut)\n","        outputs = layers.add([residual, shortcut])\n","    elif skip_connection_type == 'sum':\n","        outputs = layers.add([residual, inputs])\n","    elif skip_connection_type == 'none':\n","        outputs = residual\n","    if return_skip:\n","        return outputs, skip\n","    else:\n","        return outputs\n","\n","\n","def relu6(x):\n","    return K.relu(x, max_value=6)\n","\n","\n","def _make_divisible(v, divisor, min_value=None):\n","    if min_value is None:\n","        min_value = divisor\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_v < 0.9 * v:\n","        new_v += divisor\n","    return new_v\n","\n","\n","def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n","    in_channels = inputs._keras_shape[-1]\n","    pointwise_conv_filters = int(filters * alpha)\n","    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n","    x = inputs\n","    prefix = 'expanded_conv_{}_'.format(block_id)\n","    if block_id:\n","        # Expand\n","\n","        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n","                   use_bias=False, activation=None,\n","                   name=prefix + 'expand')(x)\n","        x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                               name=prefix + 'expand_BN')(x)\n","        x = Activation(relu6, name=prefix + 'expand_relu')(x)\n","    else:\n","        prefix = 'expanded_conv_'\n","    # Depthwise\n","    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n","                        use_bias=False, padding='same', dilation_rate=(rate, rate),\n","                        name=prefix + 'depthwise')(x)\n","    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                           name=prefix + 'depthwise_BN')(x)\n","\n","    x = Activation(relu6, name=prefix + 'depthwise_relu')(x)\n","\n","    # Project\n","    x = Conv2D(pointwise_filters,\n","               kernel_size=1, padding='same', use_bias=False, activation=None,\n","               name=prefix + 'project')(x)\n","    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n","                           name=prefix + 'project_BN')(x)\n","\n","    if skip_connection:\n","        return Add(name=prefix + 'add')([inputs, x])\n","\n","    # if in_channels == pointwise_filters and stride == 1:\n","    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pj1Vfg0rOlPd","executionInfo":{"status":"aborted","timestamp":1654626798816,"user_tz":-420,"elapsed":48,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, backbone='mobilenetv2', OS=16, alpha=1.):\n","    \"\"\" Instantiates the Deeplabv3+ architecture\n","\n","    Optionally loads weights pre-trained\n","    on PASCAL VOC. This model is available for TensorFlow only,\n","    and can only be used with inputs following the TensorFlow\n","    data format `(width, height, channels)`.\n","    # Arguments\n","        weights: one of 'pascal_voc' (pre-trained on pascal voc)\n","            or None (random initialization)\n","        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","            to use as image input for the model.\n","        input_shape: shape of input image. format HxWxC\n","            PASCAL VOC model was trained on (512,512,3) images\n","        classes: number of desired classes. If classes != 21,\n","            last layer is initialized randomly\n","        backbone: backbone to use. one of {'xception','mobilenetv2'}\n","        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}.\n","            Used only for xception backbone.\n","        alpha: controls the width of the MobileNetV2 network. This is known as the\n","            width multiplier in the MobileNetV2 paper.\n","                - If `alpha` < 1.0, proportionally decreases the number\n","                    of filters in each layer.\n","                - If `alpha` > 1.0, proportionally increases the number\n","                    of filters in each layer.\n","                - If `alpha` = 1, default number of filters from the paper\n","                    are used at each layer.\n","            Used only for mobilenetv2 backbone\n","\n","    # Returns\n","        A Keras model instance.\n","\n","    # Raises\n","        RuntimeError: If attempting to run this model with a\n","            backend that does not support separable convolutions.\n","        ValueError: in case of invalid argument for `weights` or `backbone`\n","\n","    \"\"\"\n","\n","    if not (weights in {'pascal_voc', None}):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization) or `pascal_voc` '\n","                         '(pre-trained on PASCAL VOC)')\n","\n","    if K.backend() != 'tensorflow':\n","        raise RuntimeError('The Deeplabv3+ model is only available with '\n","                           'the TensorFlow backend.')\n","\n","    if not (backbone in {'xception', 'mobilenetv2'}):\n","        raise ValueError('The `backbone` argument should be either '\n","                         '`xception`  or `mobilenetv2` ')\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    if backbone == 'xception':\n","        if OS == 8:\n","            entry_block3_stride = 1\n","            middle_block_rate = 2  # ! Not mentioned in paper, but required\n","            exit_block_rates = (2, 4)\n","            atrous_rates = (12, 24, 36)\n","        else:\n","            entry_block3_stride = 2\n","            middle_block_rate = 1\n","            exit_block_rates = (1, 2)\n","            atrous_rates = (6, 12, 18)\n","\n","        x = Conv2D(32, (3, 3), strides=(2, 2),\n","                   name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n","        x = BatchNormalization(name='entry_flow_conv1_1_BN')(x)\n","        x = Activation('relu')(x)\n","\n","        x = _conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n","        x = BatchNormalization(name='entry_flow_conv1_2_BN')(x)\n","        x = Activation('relu')(x)\n","\n","        x = _xception_block(x, [128, 128, 128], 'entry_flow_block1',\n","                            skip_connection_type='conv', stride=2,\n","                            depth_activation=False)\n","        x, skip1 = _xception_block(x, [256, 256, 256], 'entry_flow_block2',\n","                                   skip_connection_type='conv', stride=2,\n","                                   depth_activation=False, return_skip=True)\n","\n","        x = _xception_block(x, [728, 728, 728], 'entry_flow_block3',\n","                            skip_connection_type='conv', stride=entry_block3_stride,\n","                            depth_activation=False)\n","        for i in range(16):\n","            x = _xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n","                                skip_connection_type='sum', stride=1, rate=middle_block_rate,\n","                                depth_activation=False)\n","\n","        x = _xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n","                            skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n","                            depth_activation=False)\n","        x = _xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n","                            skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n","                            depth_activation=True)\n","\n","    else:\n","        OS = 8\n","        first_block_filters = _make_divisible(32 * alpha, 8)\n","        x = Conv2D(first_block_filters,\n","                   kernel_size=3,\n","                   strides=(2, 2), padding='same',\n","                   use_bias=False, name='Conv')(img_input)\n","        x = BatchNormalization(\n","            epsilon=1e-3, momentum=0.999, name='Conv_BN')(x)\n","        x = Activation(relu6, name='Conv_Relu6')(x)\n","\n","        x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n","                                expansion=1, block_id=0, skip_connection=False)\n","\n","        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n","                                expansion=6, block_id=1, skip_connection=False)\n","        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n","                                expansion=6, block_id=2, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n","                                expansion=6, block_id=3, skip_connection=False)\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n","                                expansion=6, block_id=4, skip_connection=True)\n","        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n","                                expansion=6, block_id=5, skip_connection=True)\n","\n","        # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n","                                expansion=6, block_id=6, skip_connection=False)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=7, skip_connection=True)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=8, skip_connection=True)\n","        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=9, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=10, skip_connection=False)\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=11, skip_connection=True)\n","        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n","                                expansion=6, block_id=12, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n","                                expansion=6, block_id=13, skip_connection=False)\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=14, skip_connection=True)\n","        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=15, skip_connection=True)\n","\n","        x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n","                                expansion=6, block_id=16, skip_connection=False)\n","\n","    # end of feature extractor\n","\n","    # branching for Atrous Spatial Pyramid Pooling\n","\n","    # Image Feature branch\n","    #out_shape = int(np.ceil(input_shape[0] / OS))\n","    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n","    b4 = Conv2D(256, (1, 1), padding='same',\n","                use_bias=False, name='image_pooling')(b4)\n","    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n","    b4 = Activation('relu')(b4)\n","    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n","\n","    # simple 1x1\n","    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n","    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n","    b0 = Activation('relu', name='aspp0_activation')(b0)\n","\n","    # there are only 2 branches in mobilenetV2. not sure why\n","    if backbone == 'xception':\n","        # rate = 6 (12)\n","        b1 = SepConv_BN(x, 256, 'aspp1',\n","                        rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n","        # rate = 12 (24)\n","        b2 = SepConv_BN(x, 256, 'aspp2',\n","                        rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n","        # rate = 18 (36)\n","        b3 = SepConv_BN(x, 256, 'aspp3',\n","                        rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n","\n","        # concatenate ASPP branches & project\n","        x = Concatenate()([b4, b0, b1, b2, b3])\n","    else:\n","        x = Concatenate()([b4, b0])\n","\n","    x = Conv2D(256, (1, 1), padding='same',\n","               use_bias=False, name='concat_projection')(x)\n","    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(0.1)(x)\n","\n","    # DeepLab v.3+ decoder\n","\n","    if backbone == 'xception':\n","        # Feature projection\n","        # x4 (x2) block\n","        x = BilinearUpsampling(output_size=(int(np.ceil(input_shape[0] / 4)),\n","                                            int(np.ceil(input_shape[1] / 4))))(x)\n","        dec_skip1 = Conv2D(48, (1, 1), padding='same',\n","                           use_bias=False, name='feature_projection0')(skip1)\n","        dec_skip1 = BatchNormalization(\n","            name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n","        dec_skip1 = Activation('relu')(dec_skip1)\n","        x = Concatenate()([x, dec_skip1])\n","        x = SepConv_BN(x, 256, 'decoder_conv0',\n","                       depth_activation=True, epsilon=1e-5)\n","        x = SepConv_BN(x, 256, 'decoder_conv1',\n","                       depth_activation=True, epsilon=1e-5)\n","\n","    # you can use it with arbitary number of classes\n","    if classes == 21:\n","        last_layer_name = 'logits_semantic'\n","    else:\n","        last_layer_name = 'custom_logits_semantic'\n","\n","    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n","    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","\n","    model = Model(inputs, x, name='deeplabv3+')\n","\n","    # load weights\n","\n","    if weights == 'pascal_voc':\n","        if backbone == 'xception':\n","            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH_X,\n","                                    cache_subdir='models')\n","        else:\n","            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5',\n","                                    WEIGHTS_PATH_MOBILE,\n","                                    cache_subdir='models')\n","        model.load_weights(weights_path, by_name=True)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8Zb2c-MBmQo","executionInfo":{"status":"aborted","timestamp":1654626798816,"user_tz":-420,"elapsed":47,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["class Swish(tf.keras.layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","\n","def squeeze_excite_block(reduce_ratio=0.25,name_block=None):\n","  def call(inputs):\n","    filters = inputs.shape[-1]\n","    num_reduced_filters= max(1, int(filters * reduce_ratio))\n","    se = Lambda(lambda a: K.mean(a, axis=[1,2], keepdims=True))(inputs)\n","\n","    se = Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Swish()(se)\n","    se = Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Activation('sigmoid')(se)\n","    if name_block is not None:\n","      out = Multiply(name=name_block)([se, inputs])\n","    else : \n","      out = Multiply()([se, inputs])\n","    return out\n","  return call\n","\n","def conv_block(filters,block_name=None): #kernel_size = (3,3), dilation = 1\n","  def call(inputs):\n","    x = inputs\n","\n","    x = Conv2D(filters, kernel_size=(3,3), padding=\"same\",dilation_rate =1 ,use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = Conv2D(filters, kernel_size=(3,3), padding=\"same\",dilation_rate =1, use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = squeeze_excite_block(name_block=block_name)(x)\n","\n","    return x\n","  return call"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikvcgoZ__bcI","executionInfo":{"status":"aborted","timestamp":1654626798817,"user_tz":-420,"elapsed":48,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def _ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Swish()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","    y1 = squeeze_excite_block()(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Swish()(y2)\n","    y2 = squeeze_excite_block()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Swish()(y3)\n","    y3 = squeeze_excite_block()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Swish()(y4)\n","    y4 = squeeze_excite_block()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Swish()(y5)\n","    y5 = squeeze_excite_block()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    y = BatchNormalization()(y)\n","    y = Swish()(y)\n","    y = squeeze_excite_block()(y)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkRNLZpj8PVY","executionInfo":{"status":"aborted","timestamp":1654626798818,"user_tz":-420,"elapsed":49,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def decoder_block(n_filter,skip=None):\n","  def call(inputs):\n","    x= Conv2DTranspose(n_filter, (2,2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","    out = x\n","    if skip is not None :\n","      attention = conv_block(n_filter)(skip)\n","      out = Concatenate()([x,attention])\n","    out = Dropout(0.5)(out)\n","    out = conv_block(n_filter)(out)\n","\n","    return out\n","  return call\n","  \n","def dow_block(kernel_size=(2,2),stride=(2,2)):\n","  def call(inputs):\n","    out = MaxPooling2D(kernel_size, strides=stride)(inputs)\n","    return out\n","  return call"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmwPhlbm4u2V","executionInfo":{"status":"aborted","timestamp":1654626798819,"user_tz":-420,"elapsed":50,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def encoderSegnet(input_s=(128,128,1)):\n","  inp= Input(shape=input_s)\n","  o = inp\n","  nums_filter=[64,128,256,512,512]\n","  count=0\n","  for f in nums_filter[:-1]:\n","    count+=1\n","    o = conv_block(f,block_name='output_block_'+str(count))(o) \n","    o = dow_block()(o)\n","\n","  o = conv_block(nums_filter[-1],block_name='output_block_'+str(count+1))(o)\n","  #o = Dropout(0.5)(o)\n","  return Model(inp,o)\n","\n","list_skip = [\"output_block_4\", \"output_block_3\", \"output_block_2\", \"output_block_1\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5fQBlcBKOX7","executionInfo":{"status":"aborted","timestamp":1654626798820,"user_tz":-420,"elapsed":51,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def expend_as(tensor, rep):\n","    my_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': rep})(tensor)\n","    return my_repeat\n","\n","def SalientAttentionBlock(f_maps, sal_ins, pool_maps, num_fmaps):\n","    # Inputs: feature maps from UNet, saliency images, pooled layers from UNet, number of output feature maps\n","    conv1_salins = Conv2D(128, (1, 1), activation='relu')(sal_ins)\n","    conv1_fmaps = Conv2D(128, (1, 1), strides=(2, 2), activation='relu')(f_maps)\n","    attn_add = add([conv1_fmaps,conv1_salins])\n","    conv_1d = Conv2D(128, (3, 3), activation='relu', padding='same')(attn_add)\n","    conv_1d = Conv2D(128, (3, 3), activation='relu', padding='same')(conv_1d)\n","    conv_1d = Conv2D(1, (1, 1), activation='relu')(conv_1d)\n","    conv_1d = expend_as(conv_1d,32)\n","    conv_nd = Conv2D(num_fmaps, (1, 1), activation='relu')(conv_1d)\n","    attn_act = Activation('sigmoid')(conv_nd)\n","    attn = multiply([attn_act, pool_maps])\n","    return attn\n","\n","def UNetBlock(in_fmaps, num_fmaps):\n","    # Inputs: feature maps for UNet, number of output feature maps\n","    conv1 = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(in_fmaps)\n","    conv_out = Conv2D(num_fmaps, (3, 3), activation='relu', padding='same')(conv1)\n","    return conv_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _squeeze_excite_block_(inputs, ratio=8):\n","    init = inputs\n","    channel_axis = -1\n","    filters = init.shape[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    se = GlobalAveragePooling2D()(init)\n","    se = Reshape(se_shape)(se)\n","    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","\n","    x = Multiply()([init, se])\n","    return x\n","\n","def _conv_block_(inputs, filters):\n","    x = inputs\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    x = _squeeze_excite_block_(x)\n","\n","    return x\n","\n","def encoder1(inputs):\n","    skip_connections = []\n","\n","    model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n","    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n","    for name in names:\n","        skip_connections.append(model.get_layer(name).output)\n","\n","    output = model.get_layer(\"block5_conv4\").output\n","    return output, skip_connections\n","\n","def decoder1(inputs, skip_connections):\n","    num_filters = [256, 128, 64, 32]\n","    skip_connections.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_connections[i]])\n","        x = _conv_block_(x, f)\n","\n","    return x\n","\n","def encoder2(inputs):\n","    num_filters = [32, 64, 128, 256]\n","    skip_connections = []\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = _conv_block_(x, f)\n","        skip_connections.append(x)\n","        x = MaxPool2D((2, 2))(x)\n","\n","    return x, skip_connections\n","\n","def decoder2(inputs, skip_1, skip_2):\n","    num_filters = [256, 128, 64, 32]\n","    skip_2.reverse()\n","    x = inputs\n","\n","    for i, f in enumerate(num_filters):\n","        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n","        x = Concatenate()([x, skip_1[i], skip_2[i]])\n","        x = _conv_block_(x, f)\n","\n","    return x\n","\n","def output_block(inputs):\n","    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n","    x = Activation('sigmoid')(x)\n","    return x\n","\n","def Upsample(tensor, size):\n","    \"\"\"Bilinear upsampling\"\"\"\n","    def _upsample(x, size):\n","        return tf.image.resize(images=x, size=size)\n","    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n","\n","def _ASPP_(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n","    y1 = BatchNormalization()(y1)\n","    y1 = Activation(\"relu\")(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n","    y2 = BatchNormalization()(y2)\n","    y2 = Activation(\"relu\")(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n","    y3 = BatchNormalization()(y3)\n","    y3 = Activation(\"relu\")(y3)\n","\n","    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n","    y4 = BatchNormalization()(y4)\n","    y4 = Activation(\"relu\")(y4)\n","\n","    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n","    y5 = BatchNormalization()(y5)\n","    y5 = Activation(\"relu\")(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation(\"relu\")(y)\n","\n","    return y"],"metadata":{"id":"ySy0wsJ-R8G4","executionInfo":{"status":"aborted","timestamp":1654626798821,"user_tz":-420,"elapsed":52,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KvDV_mvpTrA6"},"source":["## Attention U-Net"]},{"cell_type":"code","metadata":{"id":"djkb4I5oTt9e","executionInfo":{"status":"aborted","timestamp":1654626798821,"user_tz":-420,"elapsed":51,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","data = Input(shape=input_shape, dtype='float', name='data')\n","\n","mvn0 = BatchNormalization()(data)\n","conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n","conv1 = BatchNormalization()(conv1)\n","conv1 = Activation('relu')(conv1)\n","conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n","conv1 = BatchNormalization()(conv1)\n","conv1 = Activation('relu')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n","conv2 = BatchNormalization()(conv2)\n","conv2 = Activation('relu')(conv2)\n","conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n","conv2 = BatchNormalization()(conv2)\n","conv2 = Activation('relu')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n","conv3 = BatchNormalization()(conv3)\n","conv3 = Activation('relu')(conv3)\n","conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n","conv3 = BatchNormalization()(conv3)\n","conv3 = Activation('relu')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n","conv4 = BatchNormalization()(conv4)\n","conv4 = Activation('relu')(conv4)\n","conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n","conv4 = BatchNormalization()(conv4)\n","conv4 = Activation('relu')(conv4)\n","drop4 = Dropout(0.5)(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","#pool4 = ASPP(pool4,1024)\n","\n","conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n","conv5 = BatchNormalization()(conv5)\n","conv5 = Activation('relu')(conv5)\n","conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n","conv5 = BatchNormalization()(conv5)\n","conv5 = Activation('relu')(conv5)\n","drop5 = Dropout(0.5)(conv5)\n","\n","merge6 = attention_up_and_concate(conv5,conv4)\n","conv6 = Conv2D(512, 3,  padding = 'same')(merge6)\n","conv6 = BatchNormalization()(conv6)\n","conv6 = Activation('relu')(conv6)\n","conv6 = Conv2D(512, 3,  padding = 'same')(conv6)\n","conv6 = BatchNormalization()(conv6)\n","conv6 = Activation('relu')(conv6)\n","\n","merge7 = attention_up_and_concate(conv6,conv3)\n","conv7 = Conv2D(256, 3,  padding = 'same')(merge7)\n","conv7 = BatchNormalization()(conv7)\n","conv7 = Activation('relu')(conv7)\n","conv7 = Conv2D(256, 3,  padding = 'same')(conv7)\n","conv7 = BatchNormalization()(conv7)\n","conv7 = Activation('relu')(conv7)\n","\n","merge8 = attention_up_and_concate(conv7,conv2)\n","conv8 = Conv2D(128, 3,  padding = 'same')(merge8)\n","conv8 = BatchNormalization()(conv8)\n","conv8 = Activation('relu')(conv8)\n","conv8 = Conv2D(128, 3,  padding = 'same')(conv8)\n","conv8 = BatchNormalization()(conv8)\n","conv8 = Activation('relu')(conv8)\n","\n","merge9 = attention_up_and_concate(conv8,conv1)\n","conv9 = Conv2D(64, 3,  padding = 'same')(merge9)\n","conv9 = BatchNormalization()(conv9)\n","conv9 = Activation('relu')(conv9)\n","conv9 = Conv2D(64, 3,  padding = 'same')(conv9)\n","conv9 = BatchNormalization()(conv9)\n","conv9 = Activation('relu')(conv9)\n","conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","model = Model(data, conv10) \n","model.summary()'''\n","#0.9043"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Ky_Sm9W90Uk"},"source":["## FCN"]},{"cell_type":"code","metadata":{"id":"uQqcdoPg93N0","executionInfo":{"status":"aborted","timestamp":1654626798822,"user_tz":-420,"elapsed":52,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","inputs = Input(shape=input_shape, dtype='float', name='data')\n","\n","mvn0 = Lambda(mvn)(inputs)\n","pad0 = ZeroPadding2D(padding = 5)(mvn0)\n","\n","conv1 = Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(pad0)\n","mvn1 = Lambda(mvn)(conv1)\n","\n","conv2 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn1)\n","mvn2 = Lambda(mvn)(conv2)\n","\n","conv3 = Conv2D(64,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias =True)(mvn2)\n","mvn3 = Lambda(mvn)(conv3)\n","\n","mxp1 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn3)\n","\n","conv4 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp1)\n","mvn4 = Lambda(mvn)(conv4)\n","\n","conv5 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn4)\n","mvn5 = Lambda(mvn)(conv5)\n","\n","conv6 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn5)\n","mvn6 = Lambda(mvn)(conv6)\n","\n","conv7 = Conv2D(128,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn6)\n","mvn7 = Lambda(mvn)(conv7)\n","\n","#drop1 = Dropout(rate = 0.5)(mvn7)\n","\n","mxp2 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn7)\n","\n","conv8 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mxp2)\n","mvn8 = Lambda(mvn)(conv8)\n","\n","conv9 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn8)\n","mvn9 = Lambda(mvn)(conv9)\n","\n","conv10 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn9)\n","mvn10 = Lambda(mvn)(conv10)\n","\n","conv11 = Conv2D(256,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn10)\n","mvn11 = Lambda(mvn)(conv11)\n","\n","mxp3 = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'valid')(mvn11)\n","    \n","drop2 = Dropout(rate = 0.5)(mxp3)\n","\n","conv12 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(drop2)\n","mvn12 = Lambda(mvn)(conv12)\n","\n","conv13 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn12)\n","mvn13 = Lambda(mvn)(conv13)\n","\n","conv14 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn13)\n","mvn14 = Lambda(mvn)(conv14)\n","\n","conv15 = Conv2D(512,kernel_size = (3,3), padding = 'same', activation = 'relu',  use_bias = True)(mvn14)\n","mvn15 = Lambda(mvn)(conv15)\n","\n","drop3 = Dropout(rate = 0.5)(mvn15)\n","\n","score_conv15 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(drop3)\n","\n","upsample1 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(score_conv15)\n","#Conv2DTranspose = Deconvolution : phép biến đổi đi ngược lại tích chập \n","#từ một thứ có hình dạng đầu ra của 1 phép tích chập sang 1 thứ có hình dạng đầu vào của nó.\n","score_conv11 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn11)\n","\n","crop1 = Lambda(crop)([upsample1, score_conv11])\n","fuse1 = average([crop1, upsample1])\n","\n","upsample2 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid')(fuse1)\n","\n","score_conv7 = Conv2D(1, (1,1), strides = (1,1), use_bias = True, padding = 'valid')(mvn7)\n","\n","crop2 = Lambda(crop)([upsample2, score_conv7])\n","fuse2 = average([crop2, upsample2])\n","\n","upsample3 = Conv2DTranspose(1, (3,3), strides = (2,2), use_bias = False, padding = 'valid' )(fuse2)\n","\n","crop3 = Lambda(crop)([inputs, upsample3])\n","    \n","predict = Conv2D(1, (1,1), strides = (1,1), padding = 'valid', activation = 'sigmoid', use_bias = True)(crop3)\n","model1 = Model(inputs=inputs, outputs=predict)\n","\n","model1.summary()'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Hj2Sf2wcv5k"},"source":["## UNet with EfficientNet encoder and Residual decoder"]},{"cell_type":"code","metadata":{"id":"PhPSb6zGcvLu","executionInfo":{"status":"aborted","timestamp":1654626798822,"user_tz":-420,"elapsed":52,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","dropout_rate = 0.5\n","\n","backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","input = backbone.input\n","start_neurons = 16\n","\n","conv4 = backbone.layers[342].output\n","conv4 = Lambda(mvn)(conv4)\n","conv4 = ReLU()(conv4) #LeakyReLU(alpha=0.1)(conv4)\n","pool4 = MaxPooling2D((2, 2))(conv4)\n","pool4 = ASPP(pool4,start_neurons * 32)\n","pool4 = Dropout(dropout_rate)(pool4)\n","    \n","# Middle\n","convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","convm = residual_block(convm,start_neurons * 32)\n","convm = residual_block(convm,start_neurons * 32)\n","convm = Lambda(mvn)(convm)\n","convm = ReLU()(convm) #LeakyReLU(alpha=0.1)(convm)\n","    \n","deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","uconv4 = concatenate([deconv4, conv4])\n","uconv4 = Dropout(dropout_rate)(uconv4)\n","    \n","uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","uconv4 = residual_block(uconv4,start_neurons * 16)\n","uconv4 = residual_block(uconv4,start_neurons * 16)\n","uconv4 = Lambda(mvn)(uconv4)\n","uconv4 = ReLU()(uconv4) #LeakyReLU(alpha=0.1)(uconv4)\n","    \n","deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","conv3 = backbone.layers[154].output\n","uconv3 = concatenate([deconv3, conv3])    \n","uconv3 = Dropout(dropout_rate)(uconv3)\n","    \n","uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","uconv3 = residual_block(uconv3,start_neurons * 8)\n","uconv3 = residual_block(uconv3,start_neurons * 8)\n","uconv3 = Lambda(mvn)(uconv3)\n","uconv3 = ReLU()(uconv3) #LeakyReLU(alpha=0.1)(uconv3)\n","\n","deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","conv2 = backbone.layers[94].output\n","uconv2 = concatenate([deconv2, conv2])\n","        \n","uconv2 = Dropout(0.1)(uconv2)\n","uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","uconv2 = residual_block(uconv2,start_neurons * 4)\n","uconv2 = residual_block(uconv2,start_neurons * 4)\n","uconv2 = Lambda(mvn)(uconv2)\n","uconv2 = ReLU()(uconv2) #LeakyReLU(alpha=0.1)(uconv2)\n","    \n","deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","conv1 = backbone.layers[30].output\n","uconv1 = concatenate([deconv1, conv1])\n","    \n","uconv1 = Dropout(0.1)(uconv1)\n","uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","uconv1 = residual_block(uconv1,start_neurons * 2)\n","uconv1 = residual_block(uconv1,start_neurons * 2)\n","uconv1 = Lambda(mvn)(uconv1)\n","uconv1 = ReLU()(uconv1) #LeakyReLU(alpha=0.1)(uconv1)\n","    \n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","uconv0 = Dropout(0.1)(uconv0)\n","uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","uconv0 = residual_block(uconv0,start_neurons * 1)\n","uconv0 = residual_block(uconv0,start_neurons * 1)\n","uconv0 = Lambda(mvn)(uconv0)\n","uconv0 = ReLU()(uconv0) #LeakyReLU(alpha=0.1)(uconv0)\n","\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","uconv0 = Dropout(dropout_rate/2)(uconv0)\n","output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n","    \n","model = Model(input, output_layer)\n","model.summary()'''\n","#0.9150 "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Gx8DyAQvCgHK","executionInfo":{"status":"aborted","timestamp":1654626798823,"user_tz":-420,"elapsed":53,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WDeHmwyUtbTl"},"source":["## Proposed Model with BatchNorm"]},{"cell_type":"code","source":["def ARM(x):\n","  gp1 = AveragePooling2D(pool_size = x.shape[1])(x)\n","  gp = Conv2D(x.shape[-1],1,padding = 'valid', kernel_initializer='he_normal')(gp1)\n","  gp = BatchNormalization()(gp)\n","  gp =  Activation('sigmoid')(gp)\n","  return Multiply()([gp, x])"],"metadata":{"id":"G9if6UKlAkCD","executionInfo":{"status":"aborted","timestamp":1654626798823,"user_tz":-420,"elapsed":53,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def BGA(uconv, econv):\n","     # econv = ARM(econv)\n","     a1 = DepthwiseConv2D(kernel_size=(3, 3), padding='same', depth_multiplier=1)(econv)\n","     a2 = DepthwiseConv2D(kernel_size=(3, 3), strides= 2,padding='same', depth_multiplier=1)(econv)\n","     a1 = BatchNormalization()(a1)\n","     a2 = BatchNormalization()(a2)\n","\n","     b1 = Conv2D(uconv.shape[-1], kernel_size=(3, 3), padding='same')(uconv)\n","     b2 = DepthwiseConv2D(kernel_size=(3, 3), padding='same', depth_multiplier=1)(uconv)\n","     b1 = BatchNormalization()(b1)\n","     b2 = BatchNormalization()(b2)\n","\n","     a1 = Conv2D(a1.shape[-1], kernel_size=(1,1), padding='same', activation=None)(a1)\n","     a2 = AveragePooling2D(pool_size=(2, 2), strides=2)(a2)\n","     \n","     b1 = UpSampling2D(size=(2, 2), interpolation='nearest')(b1)\n","     b2 = AveragePooling2D(pool_size=(2, 2), strides=2)(b2)\n","     b2 = Activation('sigmoid')(b2)\n","\n","     c1 = multiply([a1, b1])\n","     c2 = multiply([a2, b2])\n","     c2 = UpSampling2D(size=(4, 4), interpolation='nearest')(c2)\n","     sum = add([c1, c2])\n","\n","     out = Conv2D(sum.shape[-1], kernel_size=(3, 3), padding='same')(sum)\n","     return BatchNormalization()(out)"],"metadata":{"id":"pePCmnzjBVWa","executionInfo":{"status":"aborted","timestamp":1654626798824,"user_tz":-420,"elapsed":53,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def FPA(x):\n","  # Global pooling branch\n","  gp1 = AveragePooling2D(pool_size = x.shape[1])(x)\n","  gp2 = Conv2D(x.shape[-1],1,padding = 'valid', kernel_initializer='he_normal')(gp1)\n","  gp3 =  Conv2DTranspose(x.shape[-1], x.shape[1], kernel_initializer='he_normal')(gp2)\n","\n","  # direct branch\n","  db = Conv2D(x.shape[-1], 1, padding = 'valid', kernel_initializer='he_normal')(x)\n","\n","  # U-shape branch\n","  max_pool_1 = MaxPooling2D(strides = 2)(x)\n","  \n","  conv7_1 = Conv2D(x.shape[-1], 7, padding = 'same', kernel_initializer='he_normal')(max_pool_1)\n","  conv7_1 = BatchNormalization()(conv7_1)\n","  conv7_1 = Activation('relu')(conv7_1)\n","  \n","  conv7_2 = Conv2D(x.shape[-1], 7, padding = 'same', kernel_initializer='he_normal')(conv7_1)\n","  conv7_2 = BatchNormalization()(conv7_2)\n","  conv7_2 = Activation('relu')(conv7_2)\n","  \n","  max_pool_2 = MaxPooling2D(strides = 2)(conv7_1)\n","  \n","  conv5_1 = Conv2D(x.shape[-1], 5, padding = 'same', kernel_initializer='he_normal')(max_pool_2)\n","  conv5_1 = BatchNormalization()(conv5_1)\n","  conv5_1 = Activation('relu')(conv5_1)\n","  \n","  conv5_2 = Conv2D(x.shape[-1], 5, padding = 'same', kernel_initializer='he_normal')(conv5_1)\n","  conv5_2 = BatchNormalization()(conv5_2)\n","  conv5_2 = Activation('relu')(conv5_2)\n","  \n","  max_pool_3 = MaxPooling2D(strides = 2)(conv5_1)\n","  \n","  conv3_1 = Conv2D(x.shape[-1], 3, padding = 'same', kernel_initializer='he_normal')(max_pool_3)\n","  conv3_1 = BatchNormalization()(conv3_1)\n","  conv3_1 = Activation('relu')(conv3_1)\n","  \n","  conv3_2 = Conv2D(x.shape[-1], 3, padding = 'same', kernel_initializer='he_normal')(conv3_1)\n","  conv3_2 = BatchNormalization()(conv3_2)\n","  conv3_2 = Activation('relu')(conv3_2)\n","  \n","  upsampled_8 = Conv2DTranspose(x.shape[-1], 2, strides = (2,2), kernel_initializer='he_normal')(conv3_2)\n","  \n","  added_1 = Add()([upsampled_8, conv5_2])\n","  \n","  upsampled_16 = Conv2DTranspose(x.shape[-1], 2, strides = (2,2), kernel_initializer='he_normal')(added_1)\n","  \n","  added_2 = Add()([upsampled_16, conv7_2])\n","  \n","  upsampled_32 = Conv2DTranspose(x.shape[-1], 2, strides = (2,2), kernel_initializer='he_normal')(added_2)\n","\n","  multiplied = Multiply()([db, upsampled_32])\n","  return Add()([multiplied, gp3])\n","\n"],"metadata":{"id":"bHOjAwAjasro","executionInfo":{"status":"aborted","timestamp":1654626798825,"user_tz":-420,"elapsed":54,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Y7NqelcBqxFy","executionInfo":{"status":"aborted","timestamp":1654626798826,"user_tz":-420,"elapsed":55,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xoxr4lLxtbTo","executionInfo":{"status":"aborted","timestamp":1654626798826,"user_tz":-420,"elapsed":55,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''\n","from tensorflow.keras.utils import get_file\n","import tensorflow as tf\n","edit: keras_utils to tf.keras.utils \n","'''\n","\n","input_shape = (256,256,3)\n","dropout_rate = 0.5\n","\n","backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","input = backbone.input\n","start_neurons = 16\n","\n","conv4 = backbone.layers[342].output\n","conv4 = BatchNormalization()(conv4)\n","conv4 = ReLU()(conv4)\n","# conv4 = FPA(conv4)\n","pool4 = MaxPooling2D((2, 2))(conv4) #272\n","# pool4 = _ASPP(pool4,272) #start_neurons * 32\n","pool4 = Dropout(dropout_rate)(pool4)\n","\n","# Middle\n","convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","convm = BatchNormalization()(convm)\n","convm = ReLU()(convm)\n","\n","uconv4 = Conv2D(272, kernel_size=(1,1),activation=None, padding='same')(convm)\n","econv4 = backbone.layers[342].output\n","bga1 = BGA(uconv4, econv4)\n","\n","uconv3 = Conv2D(112, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","econv3 = backbone.layers[154].output\n","bga2 = BGA(uconv3, econv3)\n","\n","uconv2 = Conv2D(336,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","econv2 =  backbone.layers[143].output\n","bga3 = BGA(uconv2, econv2)\n","\n","uconv1 = Conv2D(192, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","econv1 = backbone.layers[85].output\n","bga4 = BGA(uconv1, econv1)\n","\n","uconv1 = Dropout(0.1)(bga4)\n","uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","uconv1 = BatchNormalization()(uconv1)\n","uconv1 = ReLU()(uconv1)\n","    \n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","uconv0 = Dropout(0.1)(uconv0)\n","uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","uconv0 = BatchNormalization()(uconv0)\n","uconv0 = ReLU()(uconv0) \n","\n","uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","uconv0 = Dropout(dropout_rate/2)(uconv0)\n","output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# output_layer = FPA(output_layer)\n","output_layer = Activation('sigmoid')(output_layer)\n","\n","model = Model(input, output_layer)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Without ABGA"],"metadata":{"id":"YnOg-Seye7TT"}},{"cell_type":"code","source":["# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","\n","# backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","# start_neurons = 16\n","\n","# conv4 = backbone.layers[342].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# # conv4 = FPA(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) #272\n","# # pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# uconv4 = Conv2DTranspose(272, kernel_size=(3,3),strides=(2,2),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[342].output\n","# uconv4 = concatenate([uconv4, econv4])\n","# uconv4 = Dropout(dropout_rate)(uconv4)\n","\n","# uconv3 = Conv2DTranspose(112, kernel_size=(3,3),strides=(2,2), activation=None, padding='same' )(uconv4)\n","# econv3 = backbone.layers[154].output\n","# uconv3 = concatenate([uconv3, econv3])\n","# uconv3 = Dropout(dropout_rate)(uconv3)\n","\n","# uconv2 = Conv2DTranspose(336,kernel_size=(3,3),strides=(2,2), activation=None, padding='same')(uconv3)\n","# econv2 =  backbone.layers[143].output\n","# uconv2 = concatenate([uconv2, econv2])\n","# uconv2 = Dropout(dropout_rate)(uconv2)\n","\n","# uconv1 = Conv2DTranspose(192, kernel_size=(3,3),strides=(2,2), activation=None, padding='same')(uconv2)\n","# econv1 = backbone.layers[85].output\n","# uconv1 = concatenate([uconv1, econv1])\n","\n","\n","# uconv1 = Dropout(0.1)(uconv1)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# # output_layer = FPA(output_layer)\n","# output_layer = Activation('sigmoid')(output_layer)\n","\n","# model = Model(input, output_layer)\n","# model.summary()"],"metadata":{"id":"kKbF0ogBe-Gw","executionInfo":{"status":"aborted","timestamp":1654626798828,"user_tz":-420,"elapsed":56,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EffNetB0 version"],"metadata":{"id":"WnvKFgkvRMJ1"}},{"cell_type":"code","source":["# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","# start_neurons = 16\n","\n","# backbone = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","\n","# conv4 = backbone.layers[214].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) \n","# #pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# uconv4 = Conv2D(1280, kernel_size=(1,1),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[228].output\n","# bga1 = BGA(uconv4, econv4)\n","\n","# uconv3 = Conv2D(672, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","# econv3 = backbone.layers[157].output\n","# bga2 = BGA(uconv3, econv3)\n","\n","# uconv2 = Conv2D(240,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","# econv2 =  backbone.layers[71].output\n","# bga3 = BGA(uconv2, econv2)\n","\n","# uconv1 = Conv2D(144, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","# econv1 = backbone.layers[43].output\n","# bga4 = BGA(uconv1, econv1)\n","\n","# uconv1 = Dropout(0.1)(bga4)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# #output_layer = refinement_module(output_layer, 1, 64)\n","# output_layer = Activation('sigmoid')(output_layer)\n","# model = Model(input, output_layer)\n","# model.summary()\n","# #backbone.summary()"],"metadata":{"id":"SPWsoZ-URPfA","executionInfo":{"status":"aborted","timestamp":1654626798828,"user_tz":-420,"elapsed":56,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EffNetB1 version"],"metadata":{"id":"JaHdnI7JWj7a"}},{"cell_type":"code","source":["# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","# start_neurons = 16\n","\n","# backbone = EfficientNetB1(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","\n","# conv4 = backbone.layers[330].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) \n","# #pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# uconv4 = Conv2D(1280, kernel_size=(1,1),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[330].output\n","# bga1 = BGA(uconv4, econv4)\n","\n","# uconv3 = Conv2D(672, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","# econv3 = backbone.layers[229].output\n","# bga2 = BGA(uconv3, econv3)\n","\n","# uconv2 = Conv2D(240,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","# econv2 =  backbone.layers[113].output\n","# bga3 = BGA(uconv2, econv2)\n","\n","# uconv1 = Conv2D(144, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","# econv1 = backbone.layers[43].output\n","# bga4 = BGA(uconv1, econv1)\n","\n","# uconv1 = Dropout(0.1)(bga4)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# # output_layer = refinement_module(output_layer, 1, 64)\n","# output_layer = Activation('sigmoid')(output_layer)\n","# model = Model(input, output_layer)\n","# model.summary()"],"metadata":{"id":"5Ikof4YoWm4k","executionInfo":{"status":"aborted","timestamp":1654626798829,"user_tz":-420,"elapsed":57,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EffNetB2 version"],"metadata":{"id":"rrade1KziI7s"}},{"cell_type":"code","source":["# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","# start_neurons = 16\n","\n","# backbone = EfficientNetB2(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","\n","# conv4 = backbone.layers[330].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) \n","# #pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# uconv4 = Conv2D(1408, kernel_size=(1,1),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[330].output\n","# bga1 = BGA(uconv4, econv4)\n","\n","# uconv3 = Conv2D(720, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","# econv3 = backbone.layers[229].output\n","# bga2 = BGA(uconv3, econv3)\n","\n","# uconv2 = Conv2D(288,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","# econv2 =  backbone.layers[113].output\n","# bga3 = BGA(uconv2, econv2)\n","\n","# uconv1 = Conv2D(144, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","# econv1 = backbone.layers[70].output\n","# bga4 = BGA(uconv1, econv1)\n","\n","# uconv1 = Dropout(0.1)(bga4)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# # output_layer = refinement_module(output_layer, 1, 64)\n","# output_layer = Activation('sigmoid')(output_layer)\n","# model = Model(input, output_layer)\n","# model.summary()\n"],"metadata":{"id":"FM8heS0tiL0v","executionInfo":{"status":"aborted","timestamp":1654626798829,"user_tz":-420,"elapsed":57,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#EffNetB3 version"],"metadata":{"id":"CR84pVY9r6ZG"}},{"cell_type":"code","source":["# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","# start_neurons = 16\n","\n","# backbone = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","\n","# conv4 = backbone.layers[375].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) \n","# #pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# uconv4 = Conv2D(1536, kernel_size=(1,1),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[375].output\n","# bga1 = BGA(uconv4, econv4)\n","\n","# uconv3 = Conv2D(816, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","# econv3 = backbone.layers[259].output\n","# bga2 = BGA(uconv3, econv3)\n","\n","# uconv2 = Conv2D(288,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","# econv2 =  backbone.layers[113].output\n","# bga3 = BGA(uconv2, econv2)\n","\n","# uconv1 = Conv2D(192, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","# econv1 = backbone.layers[70].output\n","# bga4 = BGA(uconv1, econv1)\n","\n","# uconv1 = Dropout(0.1)(bga4)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# # output_layer = refinement_module(output_layer, 1, 64)\n","# output_layer = Activation('sigmoid')(output_layer)\n","# model = Model(input, output_layer)\n","# model.summary()"],"metadata":{"id":"xjRrtMaSr8pN","executionInfo":{"status":"aborted","timestamp":1654626798829,"user_tz":-420,"elapsed":57,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#EffNet B4 version"],"metadata":{"id":"i1H1LyI60iTa"}},{"cell_type":"code","source":["\n","# '''\n","# from tensorflow.keras.utils import get_file\n","# import tensorflow as tf\n","# edit: keras_utils to tf.keras.utils \n","# '''\n","\n","# input_shape = (256,256,3)\n","# dropout_rate = 0.5\n","# start_neurons = 16\n","\n","# backbone = EfficientNetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","# input = backbone.input\n","\n","# conv4 = backbone.layers[465].output\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = ReLU()(conv4)\n","# pool4 = MaxPooling2D((2, 2))(conv4) \n","# #pool4 = _ASPP(pool4,272) #start_neurons * 32\n","# pool4 = Dropout(dropout_rate)(pool4)\n","\n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n","# convm = BatchNormalization()(convm)\n","# convm = ReLU()(convm)\n","\n","# # convm = FPA(convm)\n","\n","# uconv4 = Conv2D(1792, kernel_size=(1,1),activation=None, padding='same')(convm)\n","# econv4 = backbone.layers[465].output\n","# bga1 = BGA(uconv4, econv4)\n","\n","# uconv3 = Conv2D(960, kernel_size=(1,1), activation=None, padding='same' )(bga1)\n","# econv3 = backbone.layers[319].output\n","# bga2 = BGA(uconv3, econv3)\n","\n","# uconv2 = Conv2D(336,kernel_size=(1,1), activation=None, padding='same')(bga2)\n","# econv2 =  backbone.layers[143].output\n","# bga3 = BGA(uconv2, econv2)\n","\n","# uconv1 = Conv2D(192, kernel_size=(1,1), activation=None, padding='same')(bga3)\n","# econv1 = backbone.layers[85].output\n","# bga4 = BGA(uconv1, econv1)\n","\n","# uconv1 = Dropout(0.1)(bga4)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = BatchNormalization()(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.1)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = BatchNormalization()(uconv0)\n","# uconv0 = ReLU()(uconv0) \n","\n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv0)  \n","# uconv0 = Dropout(dropout_rate/2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv0)  \n","# # output_layer = refinement_module(output_layer, 1, 64)\n","# output_layer = Activation('sigmoid')(output_layer)\n","# model = Model(input, output_layer)\n","# model.summary()"],"metadata":{"id":"J_gpr-Aq0lLs","executionInfo":{"status":"aborted","timestamp":1654626798830,"user_tz":-420,"elapsed":58,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBQgiYIcyXvG"},"source":["## Salient Attention Unet (based SOD)"]},{"cell_type":"code","metadata":{"id":"6Mw7mc_5ybHu","executionInfo":{"status":"aborted","timestamp":1654626798830,"user_tz":-420,"elapsed":57,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","\n","conv1 = UNetBlock(input, 64)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    \n","input2 = Input(shape=input_shape) #not having saliency map\n","    \n","dwns1 = MaxPooling2D(2,2)(input2)\n","attn1 = SalientAttentionBlock(conv1, dwns1, pool1, 64)\n","\n","conv2 = UNetBlock(attn1, 64)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","dwns2 = MaxPooling2D(4,4)(input2)\n","attn2 = SalientAttentionBlock(conv2, dwns2, pool2, 64)\n","\n","conv3 = UNetBlock(attn2, 128)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","dwns3 = MaxPooling2D(8,8)(input2)\n","attn3 = SalientAttentionBlock(conv3, dwns3, pool3, 128)\n","\n","conv4 = UNetBlock(attn3, 128)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","dwns4 = MaxPooling2D(16,16)(input2)\n","attn4 = SalientAttentionBlock(conv4, dwns4, pool4, 128)\n","\n","conv5 = UNetBlock(attn4, 256)\n","pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n","\n","dwns5 = MaxPooling2D(32,32)(input2)\n","attn5 = SalientAttentionBlock(conv5, dwns5, pool5, 256)\n","\n","conv6 = UNetBlock(attn5, 256)\n","pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n","\n","dwns6 = MaxPooling2D(64,64)(input2)\n","attn6 = SalientAttentionBlock(conv6, dwns6, pool6, 256)\n","\n","conv7 = UNetBlock(attn6, 512)\n","\n","up8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), attn5], axis=3)\n","conv8 = UNetBlock(up8, 256)\n","\n","up9 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv8), attn4], axis=3)\n","conv9 = UNetBlock(up9, 256)\n","\n","up10 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv9), attn3], axis=3)\n","conv10 = UNetBlock(up10, 128)\n","\n","up11 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv10), attn2], axis=3)\n","conv11 = UNetBlock(up11, 128)\n","\n","up12 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv11), attn1], axis=3)\n","conv12 = UNetBlock(up12, 64)\n","\n","up13 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n","conv13 = UNetBlock(up13, 64)\n","\n","conv14 = Conv2D(1, (1, 1), activation='sigmoid')(conv13)\n","model = Model(inputs = [input, input2], outputs = conv14)\n","model.summary()'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlgBqYz83sqZ"},"source":["## Seg-UNet"]},{"cell_type":"code","metadata":{"id":"9MmIu2lug_lf","executionInfo":{"status":"aborted","timestamp":1654626798830,"user_tz":-420,"elapsed":57,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","encoder = encoderSegnet(input_s = input_shape)\n","skip_connect=[encoder.get_layer(i).output for i in list_skip]\n","num_filters = [512,256, 128, 64]\n","\n","o = encoder.output\n","o = _ASPP(o,128)\n","  \n","for i, f in enumerate(num_filters):\n","  o = decoder_block(f,skip=skip_connect[i])(o)\n","  \n","o = Conv2D(1,(3, 3), padding='same', kernel_initializer='he_normal')(o)\n","# yn = Activation('softmax')(o[...,:-1])\n","# bn = o[...,-1:]\n","# output = Concatenate()([yn,bn])\n","#if out_channels > 1 : \n","  #output = Activation('softmax', name = 'softmax')(o)\n","#else :\n","output = Activation('sigmoid', name = 'sigmoid')(o)\n","model4 = Model(encoder.input,output)\n","model4.summary()'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzAyEyor3Xci"},"source":["## ResUNet"]},{"cell_type":"code","metadata":{"id":"hw3ZZVp03WZL","executionInfo":{"status":"aborted","timestamp":1654626798831,"user_tz":-420,"elapsed":58,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# f = [16, 32, 64, 128, 256]\n","# input_shape = (256,256,3)\n","# inputs = Input(shape=input_shape, dtype='float', name='data')\n","\n","# ## ENCODER \n","# e0 = inputs\n","# e1 = stem(e0, f[0])\n","# e2 = _residual_block(e1, f[1], strides=2)\n","# e3 = _residual_block(e2, f[2], strides=2)\n","# e4 = _residual_block(e3, f[3], strides=2)\n","# e5 = _residual_block(e4, f[4], strides=2)\n","\n","# # BRIDGE\n","# b0 = _conv_block(e5, f[4], strides=1)\n","# b1 = _conv_block(b0, f[4], strides=1)\n","\n","# # DECODER \n","# u1 = upsample_concat_block(b1, e4)\n","# d1 = _residual_block(u1, f[4])\n","\n","# u2 = upsample_concat_block(d1, e3)\n","# d2 = _residual_block(u2, f[3])\n","\n","# u3 = upsample_concat_block(d2, e2)\n","# d3 = _residual_block(u3, f[2])\n","\n","# u4 = upsample_concat_block(d3, e1)\n","# d4 = _residual_block(u4, f[1])\n","\n","# outputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(d4)\n","# model = Model(inputs, outputs)\n","\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52QrHPPLGPGw"},"source":["## EfficientUNet B0-B7"]},{"cell_type":"code","metadata":{"id":"eVo0GwaNGR7j","executionInfo":{"status":"aborted","timestamp":1654626798831,"user_tz":-420,"elapsed":58,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["#%run /content/drive/MyDrive/brain_mri_segmentation/EfficientUNet.ipynb #0.9100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohtCA6lmz2F3","executionInfo":{"status":"aborted","timestamp":1654626798831,"user_tz":-420,"elapsed":58,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["#model2 = get_efficient_unet_b2((256,256,3), pretrained=True, block_type='transpose', concat_input=True,out_channels=1)\n","#model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KyJ2U-32eULg"},"source":["## DeepLab V3"]},{"cell_type":"code","metadata":{"id":"AcbFJBVBeyIx","executionInfo":{"status":"aborted","timestamp":1654626798832,"user_tz":-420,"elapsed":59,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_tensor=input)\n","x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n","x = DilatedSpatialPyramidPooling(x)\n","\n","input_a = layers.UpSampling2D(size=(256 // 4 // x.shape[1], 256 // 4 // x.shape[2]),interpolation=\"bilinear\",)(x)\n","input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n","input_b = _convolution_block(input_b, num_filters=48, kernel_size=1)\n","\n","x = layers.Concatenate(axis=-1)([input_a, input_b])\n","x = _convolution_block(x)\n","x = _convolution_block(x)\n","x = layers.UpSampling2D(size=(256 // x.shape[1], 256 // x.shape[2]),interpolation=\"bilinear\",)(x)\n","model_output = layers.Conv2D(1, kernel_size=(1, 1), padding=\"same\")(x)\n","model = Model(inputs=input, outputs=model_output)\n","model = Deeplabv3(input_shape=(256,256,3),backbone=\"mobilenetv2\", classes=1)\n","model.summary()'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLddzLS0afYd"},"source":["## Swin U-Net"]},{"cell_type":"code","metadata":{"id":"DX9tK6i7aeoG","executionInfo":{"status":"aborted","timestamp":1654626798832,"user_tz":-420,"elapsed":58,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# filter_num_begin = 32     # number of channels in the first downsampling block; it is also the number of embedded dimensions\n","# depth = 4                  # the depth of SwinUNET; depth=4 means three down/upsampling levels and a bottom level \n","# stack_num_down = 2         # number of Swin Transformers per downsampling level\n","# stack_num_up = 2           # number of Swin Transformers per upsampling level\n","# patch_size = (4, 4)        # Extract 2-by-2 patches from the input image. Height and width of the patch must be equal.\n","# num_heads = [4, 8, 8, 8]   # number of attention heads per down/upsampling level\n","# window_size = [4, 2, 2, 2] # the size of attention window per down/upsampling level\n","# num_mlp = 512              # number of MLP nodes within the Transformer\n","# shift_window=True          # Apply window shifting, i.e., Swin-MSA\n","\n","# model = models.swin_unet_2d(input_size=(256,256,3), filter_num_begin=filter_num_begin, n_labels=1, depth=depth, stack_num_down=stack_num_down, stack_num_up=stack_num_up, \n","#                       patch_size=patch_size, num_heads=num_heads, window_size=window_size, num_mlp=num_mlp, output_activation='Sigmoid', shift_window=True, name='swin_unet')\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsG4QWY3cchZ"},"source":["## TransU-Net"]},{"cell_type":"code","metadata":{"id":"wcHHsNDbcfjj","executionInfo":{"status":"aborted","timestamp":1654626798833,"user_tz":-420,"elapsed":59,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''model = models.transunet_2d(input_size=(256,256,3), filter_num=[32, 64, 128, 256], n_labels=1, stack_num_down=2, stack_num_up=2,\n","                 embed_dim=768, num_mlp = 3072, num_heads=12, num_transformer=12,\n","                 activation='ReLU', mlp_activation='GELU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True, \n","                 backbone=None, weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='transunet')\n","model.summary()'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_EQP0AkXi0Gi"},"source":["## U-Net++"]},{"cell_type":"code","metadata":{"id":"-EfiEYyRiyrb","executionInfo":{"status":"aborted","timestamp":1654626798835,"user_tz":-420,"elapsed":61,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# start_neurons = 8\n","\n","# input_shape = (256,256,3)\n","# data = Input(shape=input_shape, dtype='float', name='data')\n","\n","# mvn0 = BatchNormalization()(data)\n","# conv0 = Conv2D(8, 3, padding = 'same')(mvn0)\n","# conv0 = BatchNormalization()(conv0)\n","# conv0 = Activation('relu')(conv0)\n","# conv0 = Conv2D(8, 3,  padding = 'same')(conv0)\n","# conv0 = BatchNormalization()(conv0)\n","# conv0 = Activation('relu')(conv0)\n","# pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n","\n","# conv1 = Conv2D(16, 3,  padding = 'same')(pool0)\n","# conv1 = BatchNormalization()(conv1)\n","# conv1 = Activation('relu')(conv1)\n","# conv1 = Conv2D(16, 3,  padding = 'same')(conv1)\n","# conv1 = BatchNormalization()(conv1)\n","# conv1 = Activation('relu')(conv1)\n","# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","# conv2 = Conv2D(32, 3,  padding = 'same')(pool1)\n","# conv2 = BatchNormalization()(conv2)\n","# conv2 = Activation('relu')(conv2)\n","# conv2 = Conv2D(32, 3,  padding = 'same')(conv2)\n","# conv2 = BatchNormalization()(conv2)\n","# conv2 = Activation('relu')(conv2)\n","# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    \n","# conv3 = Conv2D(64, 3,  padding = 'same')(pool2)\n","# conv3 = BatchNormalization()(conv3)\n","# conv3 = Activation('relu')(conv3)\n","# conv3 = Conv2D(64, 3,  padding = 'same')(conv3)\n","# conv3 = BatchNormalization()(conv3)\n","# conv3 = Activation('relu')(conv3)\n","# pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","# conv4 = Conv2D(128, 3,  padding = 'same')(pool3)\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = Activation('relu')(conv4)\n","# conv4 = Conv2D(128, 3,  padding = 'same')(conv4)\n","# conv4 = BatchNormalization()(conv4)\n","# conv4 = Activation('relu')(conv4)\n","# drop4 = Dropout(0.5)(conv4)\n","# pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","    \n","# # Middle\n","# convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\",name='conv_middle')(pool4)\n","# convm = ReLU()(convm)\n","    \n","# deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","# deconv4_up1 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4)\n","# deconv4_up2 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up1)\n","# deconv4_up3 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(deconv4_up2)\n","# uconv4 = concatenate([deconv4, conv4])\n","# uconv4 = Dropout(0.5)(uconv4) \n","    \n","# uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","# uconv4 = ReLU()(uconv4)  #conv1_2\n","    \n","# deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","# deconv3_up1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n","# deconv3_up2 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(deconv3_up1)\n","# uconv3 = concatenate([deconv3,deconv4_up1, conv3])    \n","# uconv3 = Dropout(0.5)(uconv3)\n","    \n","# uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","# uconv3 = ReLU()(uconv3)\n","# deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","# deconv2_up1 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n","# uconv2 = concatenate([deconv2,deconv3_up1,deconv4_up2, conv2])\n","        \n","# uconv2 = Dropout(0.2)(uconv2)\n","# uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","# uconv2 = ReLU()(uconv2)\n","    \n","# deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","# uconv1 = concatenate([deconv1,deconv2_up1,deconv3_up2,deconv4_up3, conv1])\n","# uconv1 = Dropout(0.2)(uconv1)\n","# uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","# uconv1 = ReLU()(uconv1)\n","    \n","# uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","# uconv0 = Dropout(0.2)(uconv0)\n","# uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","# uconv0 = ReLU()(uconv0)\n","    \n","# uconv0 = Dropout(0.2)(uconv0)\n","# output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n","    \n","# model = Model(data, output_layer)\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPiu7yXRoGl9"},"source":["## PraNet"]},{"cell_type":"code","metadata":{"id":"MOWiUNFVoGmB","executionInfo":{"status":"aborted","timestamp":1654626798836,"user_tz":-420,"elapsed":62,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["'''input_shape = (256,256,3)\n","input = Input(shape=input_shape)\n","\n","fe_backbone = FE_backbone(model_architecture='resnet50', inshape=input_shape, is_trainable=True)\n","backbone_feature_extractor = fe_backbone.get_fe_backbone()\n","features = backbone_feature_extractor(input)\n","\n","# RFB\n","feat2_rfb = RFB(filters=32, name=\"rfb_2\")(features[1])  # => level_2(batch,h/8,w/8,32)\n","feat3_rfb = RFB(filters=32, name=\"rfb_3\")(features[2])  # => level_3(batch,h/16,w/16,32)\n","feat4_rfb = RFB(filters=32, name=\"rfb_4\")(features[3])  # => level_4(batch,h/32,w/32,32)\n","\n","# Partial decoder \n","sg = PartialDecoder(filters=32, name=\"partial_decoder\")(feat4_rfb, feat3_rfb, feat2_rfb) # => (batch,h/8,w/8,1) Global saliency map\n","lateral_out_sg = preprocessing.Resizing(256, 256, name='salient_out_5')(sg) # resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 5\n","\n","# reverse attention branch 4 \n","resized_sg = preprocessing.Resizing(256//32, 256//32, name=\"resize4\")(sg) # resize (batch, h/8,w/8,1) => (batch, h/32,w/32,1)\n","s4 = ReverseAttention(filters=256, kernel_size=(5, 5),branch='gsmap', name=\"reverse_attention_br4\")(features[3],resized_sg)\n","lateral_out_s4 = preprocessing.Resizing(256, 256, name=\"salient_out_4\")(s4) # resize (batch,h/32,w/32,1) => (batch,h,w,1) #out 4\n","\n","# reverse attention branch 3\n","resized_s4 = preprocessing.Resizing(256//16, 256//16, name=\"resize3\")(s4) # resize (batch, h/32,w/32,1) => (batch, h/16,w/16,1)\n","s3 = ReverseAttention(filters=64, name=\"reverse_attention_br3\")(features[2],resized_s4)\n","lateral_out_s3 = preprocessing.Resizing(256, 256, name=\"salient_out_3\")(s3) # resize (batch,h/16,w/16,1) => (batch,h,w,1) #out 3\n","\n","# reverse attention branch 2\n","resized_s3 = preprocessing.Resizing(256//8, 256//8, name=\"resize2\")(s3)# resize (batch, h/16,w/16,1) => (batch, h/8,w/8,1)\n","s2 = ReverseAttention(filters=64, name=\"reverse_attention_br2\")(features[1],resized_s3)\n","lateral_out_s2 = preprocessing.Resizing(256, 256, name=\"final_salient_out_2\")(s2)# resize (batch,h/8,w/8,1) => (batch,h,w,1) #out 2\n","lateral_out_s2 = Activation('sigmoid')(lateral_out_s2)\n","\n","model = Model(inputs = input, outputs = lateral_out_s2)\n","model.summary()'''\n","#0.8916"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Double U-Net"],"metadata":{"id":"kdV1LNnyReuH"}},{"cell_type":"code","source":["# input_shape = (256,256,3)\n","# inputs = Input(input_shape)\n","# x, skip_1 = encoder1(inputs)\n","# x = _ASPP_(x, 64)\n","# x = decoder1(x, skip_1)\n","# outputs1 = output_block(x)\n","\n","# x = inputs * outputs1\n","\n","# x, skip_2 = encoder2(x)\n","# x = _ASPP_(x, 64)\n","# x = decoder2(x, skip_1, skip_2)\n","# outputs2 = output_block(x)\n","# outputs = Concatenate()([outputs1, outputs2])\n","\n","# model3 = Model(inputs, outputs)\n","# model3.summary()"],"metadata":{"id":"tBKkjKl-RhSJ","executionInfo":{"status":"aborted","timestamp":1654626798837,"user_tz":-420,"elapsed":63,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxV40RuFDL7T"},"source":["## Metric"]},{"cell_type":"code","metadata":{"id":"PMFm7bcTWq3O","executionInfo":{"status":"aborted","timestamp":1654626798838,"user_tz":-420,"elapsed":64,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def dice_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average dice coefficient per batch.'''\n","    #y_true = tf.one_hot(tf.squeeze(tf.cast(y_true, tf.uint8), axis=-1), depth=2)\n","    #y_true = tf.cast(y_true, tf.float32)\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    intersection = K.sum(y_true * y_pred)\n","    summation = K.sum(y_true + y_pred)\n","    return (2.0 * intersection + smooth) / (summation + smooth)\n","\n","def jaccard_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average jaccard coefficient per batch.'''\n","    #y_true = tf.one_hot(tf.squeeze(tf.cast(y_true, tf.uint8), axis=-1), depth=2)\n","    #y_true = tf.cast(y_true, tf.float32)\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    intersection = K.sum(y_true * y_pred)\n","    union = K.sum(y_true + y_pred) - intersection\n","    return (intersection + smooth) / (union + smooth)\n","\n","def TP(target, output, smooth=1e-10):\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","    true_pos = K.sum(target_positive * output_positive)\n","\n","    return true_pos\n","\n","def TN(target, output, smooth=1e-10):\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","\n","    return true_neg\n","\n","def FP(target, output, smooth=1e-10):\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    return false_pos\n","\n","def FN(target, output, smooth=1e-10):\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","\n","    return false_neg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtVESQvjXwd8","executionInfo":{"status":"aborted","timestamp":1654626798839,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["def dice_coef_loss(y_true, y_pred, smooth=1e-10):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    intersection = K.sum(y_true * y_pred)\n","    summation = K.sum(y_true + y_pred)\n","    return 1-(2.0 * intersection + smooth) / (summation + smooth)\n","\n","def IoU_loss(y_true, y_pred, smooth=1e-10):\n","    '''Average jaccard coefficient per batch.'''\n","    #y_true = tf.one_hot(tf.squeeze(tf.cast(y_true, tf.uint8), axis=-1), depth=2)\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    intersection = K.sum(y_true * y_pred)\n","    union = K.sum(y_true + y_pred) - intersection\n","    return 1-(intersection + smooth) / (union + smooth)\n","\n","def tversky_loss(target, output):\n","    #target = tf.one_hot(tf.squeeze(tf.cast(target, tf.uint8), axis=-1), depth=2)\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","    alpha = 0.7\n","    loss = 1-(true_pos)/(true_pos + alpha*false_neg + (1-alpha)*false_pos)\n","    return loss\n","\n","def focal_tversky(target, output):\n","    p = tversky_loss(target, output)\n","    gamma = 0.75\n","    return K.pow(p, gamma)\n","\n","def tversky_kahneman(target, output):\n","    alpha=0.5; beta=0.5; gamma=4/3; smooth=1e-10;\n","    #target = tf.one_hot(tf.squeeze(tf.cast(target, tf.uint8), axis=-1), depth=2)\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","    _true_pos = K.sqrt(true_pos*true_neg)\n","\n","    p = (0.5*_true_pos + 0.5*true_neg)/(0.5*_true_pos + 0.5*true_neg + alpha*false_pos + beta*false_neg)  \n","    p_gamma = K.pow(p,gamma) #p^gamma\n","    _p_gamma = K.pow(1-p, gamma) #(1-p)^gamma\n","    loss = _p_gamma/K.pow(p_gamma + _p_gamma, 1/gamma)\n","    return loss\n","\n","def accuracy_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    a = 1-(true_pos + true_neg)/(true_pos + true_neg + false_pos + false_neg)\n","    return a\n","\n","def bce_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    _target = K.flatten(target)\n","    _output = K.flatten(output)\n","\n","    loss = binary_crossentropy(_target, _output)\n","    return loss\n","\n","def bub_loss(target, output):\n","    #target = tf.one_hot(tf.squeeze(tf.cast(target, tf.uint8), axis=-1), depth=2)\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","    _true_neg = K.sqrt(true_pos*true_neg)\n","\n","    b = 1-(true_pos + _true_neg)/(true_pos + _true_neg + false_pos + false_neg)\n","    return b"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dice_1_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    loss = 1 - true_pos / (true_pos + false_neg)\n","    return loss\n","\n","def dice_2_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    loss = 1-true_pos / (true_pos + false_pos)\n","    return loss\n","\n","def swjaccard_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    loss = 1 - 3*true_pos / (3*true_pos + false_neg + false_pos)\n","    return loss\n","\n","def Kulczynski_1_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    loss = 1 - true_pos / (false_pos + false_neg)\n","    return loss\n","\n","def Kulczynski_2_loss(target, output):\n","    target = tf.cast(target, tf.float32)\n","    target_positive = K.flatten(target)\n","    output_positive = K.flatten(output)\n","\n","    true_pos = K.sum(target_positive * output_positive)\n","    true_neg = K.sum((1-target_positive) * (1-output_positive))\n","    false_neg = K.sum(target_positive * (1-output_positive))\n","    false_pos = K.sum((1-target_positive) * output_positive)\n","\n","    loss = 1 - 0.5*(true_pos/(true_pos + false_neg) + true_pos/(true_pos + false_pos))\n","    return loss\n","\n","def driver_kroeber_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos / (np.sqrt((true_pos + false_neg)*(true_pos + false_pos)))\n","  return loss\n","\n","def braun_blanquet(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos/(np.max((true_pos + false_neg, true_pos + false_pos)))\n","  return loss\n","\n","def simpson_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos/(np.min((true_pos + false_neg, true_pos + false_pos)))\n","\n","def Sorgenfrei_loss(target, input):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos*true_pos / ((true_pos + false_neg)*(true_pos + false_pos))\n","  return loss\n","\n","def Mountford_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - 2*true_pos / (true_pos*(false_neg + false_pos) + 2*false_pos*false_neg)\n","  return loss\n","\n","def fager_mcgowan_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - (true_pos / (np.sqrt((true_pos + false_neg)*(true_pos + false_pos))) - np.max((true_pos + false_neg, true_pos + false_pos)) / 2)\n","  return loss\n","\n","def sokal_sneath_1_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos / (true_pos + 2*(false_neg + false_pos))\n","  return loss\n","\n","def mcconaughey_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - (true_pos*true_pos - false_neg*false_pos) / ((true_pos + false_neg)*(true_pos + false_pos))\n","  return loss\n","\n","def johnson_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos*(1/(true_pos + false_neg) + 1/(true_pos + false_pos))\n","  return loss\n","\n","def van_der_maarel_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - (2*true_pos - false_neg - false_pos)/(2*true_pos + false_neg + false_pos)\n","  return loss\n","\n","def consonni_todeschini_1_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - np.log(1 + true_pos)/np.log(1 + true_pos + false_neg + false_pos)\n","  return loss\n","\n","def rushell_rao_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - true_pos / (true_pos + false_neg + false_pos + true_neg)\n","  return loss\n","\n","def consonni_todeschini_2_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - np.log(1 + true_pos)/np.log(1 + true_pos + false_neg + false_pos + true_neg)\n","  return loss\n","\n","def sokal_michener_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - (true_pos + true_neg) / (true_pos + false_neg + false_pos + true_neg)\n","  return loss\n","\n","def rogers_tanimoto_loss(target, output):\n","  target = tf.cast(target, tf.float32)\n","  target_positive = K.flatten(target)\n","  output_positive = K.flatten(output)\n","\n","  true_pos = K.sum(target_positive * output_positive)\n","  true_neg = K.sum((1-target_positive) * (1-output_positive))\n","  false_neg = K.sum(target_positive * (1-output_positive))\n","  false_pos = K.sum((1-target_positive) * output_positive)\n","\n","  loss = 1 - (true_pos + true_neg) / (true_pos + 2*false_neg + 2*false_pos + true_neg)\n","  return loss"],"metadata":{"id":"j1hUq__ycjgL","executionInfo":{"status":"aborted","timestamp":1654626798840,"user_tz":-420,"elapsed":66,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Ge1I7r9Ylam"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"LlpSRbqnDL7U","executionInfo":{"status":"aborted","timestamp":1654626798840,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["# compling model and callbacks functions\n","nadam = tf.keras.optimizers.Nadam(0.005)\n","model.compile(optimizer = nadam, loss = Kulczynski_2_loss, metrics = [jaccard_coef, dice_coef])\n","#model1.compile(optimizer = nadam, loss = tversky_kahneman, metrics = [jaccard_coef, dice_coef]) #tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n","#model2.compile(optimizer = nadam, loss = tversky_kahneman, metrics = [jaccard_coef, dice_coef])\n","#model3.compile(optimizer = nadam, loss = tversky_kahneman, metrics = [jaccard_coef, dice_coef])\n","#model4.compile(optimizer = nadam, loss = tversky_kahneman, metrics = [jaccard_coef, dice_coef])\n","#model5.compile(optimizer = nadam, loss = tversky_kahneman, metrics = [jaccard_coef, dice_coef])\n","\n","#callbacks\n","earlystopping = EarlyStopping(monitor='val_loss',\n","                              mode='min', \n","                              verbose=1, \n","                              patience=20)\n","# save the best model with lower validation loss\n","checkpointer = ModelCheckpoint(filepath=\"/content/drive/MyDrive/brain_mri_segmentation/weights/cell/weight.h5\", \n","                               monitor=\"val_loss\",\n","                               verbose=1, \n","                               save_best_only=True) #filepath=\"/content/drive/MyDrive/brain_mri_segmentation/weight/weight.h5\"\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                              mode='min',\n","                              verbose=1,\n","                              patience=8,\n","                              min_delta=0.0001,\n","                              min_lr=1e-5,\n","                              factor=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWrZ4W9ODL7U","executionInfo":{"status":"aborted","timestamp":1654626798840,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["h = model.fit(x_train, y_train, validation_data = [x_test,y_test], batch_size=8, epochs = 200, callbacks = [checkpointer, reduce_lr])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2LxgFD27vThN"},"source":["## Drawing for Checking"]},{"cell_type":"code","metadata":{"id":"iGTupst4DL7U","executionInfo":{"status":"aborted","timestamp":1654626798841,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"source":["from matplotlib.backends.backend_pdf import PdfPages\n","\n","# model1.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weight/fcn_cell_weight.h5')\n","# model2.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weight/effunet_cell_weight.h5')\n","# model3.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weight/doubleunet_cell_weight.h5')\n","# model4.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weight/seg_unet_cell_weight.h5')\n","# model5.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weight/proposed_cell_weight.h5')\n","model.load_weights('/content/drive/MyDrive/brain_mri_segmentation/weights/cell/weight.h5')\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(4, 3, figsize = (20,30), dpi=300)\n","for i in range(4):\n","  y_pred = model(x_test[i:i+1])\n","  # plt.subplot(131),plt.imshow(x_test[i]), plt.axis('off')\n","  # plt.subplot(132),plt.imshow(y_pred[0,...,0],cmap ='gray'), plt.axis('off')\n","  # plt.subplot(133),plt.imshow(y_test[i,...,0],cmap='gray'), plt.axis('off')\n","  axs[i, 0].imshow(x_test[i])\n","  axs[i, 1].imshow(y_pred[0,...,0],cmap ='gray')\n","  axs[i, 2].imshow(y_test[i,...,0],cmap='gray')\n","  axs[i, 0].set_axis_off()\n","  axs[i, 1].set_axis_off()\n","  axs[i, 2].set_axis_off()\n","plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","axs[0,0].set_title('Input Image',x=0.5, y=1.1, fontsize=50)\n","axs[0,1].set_title('Ground Truth',x=0.5, y=1.1, fontsize=50)\n","axs[0,2].set_title('Prediction',x=0.5, y=1.1, fontsize=50)\n","plt.savefig(f'/content/drive/MyDrive/brain_mri_segmentation/weights/fig/data.pdf', bbox_inches='tight', pad_inches=0)"],"metadata":{"id":"HHVQlxWlkfja","executionInfo":{"status":"aborted","timestamp":1654626798841,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["h.history.keys()"],"metadata":{"id":"aCWSizIgr4MZ","executionInfo":{"status":"aborted","timestamp":1654626798842,"user_tz":-420,"elapsed":66,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(3, 1, figsize = (20,25), dpi=100)\n","axs[0].plot(h.history['dice_coef'])\n","axs[0].plot(h.history['val_dice_coef'])\n","axs[0].legend(['train', 'validation'], loc='lower right', fontsize = 20)\n","axs[0].set_title('model accuracy',x=0.5, y=1,fontsize=40)\n","axs[0].tick_params(axis='both', which='major', labelsize=20)\n","\n","axs[1].plot(h.history['jaccard_coef'])\n","axs[1].plot(h.history['val_jaccard_coef'])\n","axs[1].legend(['train', 'validation'], loc='lower right', fontsize = 20)\n","axs[1].set_title('model IoU',x=0.5, y=1, fontsize=40)\n","axs[1].tick_params(axis='both', which='major', labelsize=20)\n","axs[2].plot(h.history['loss'])\n","axs[2].plot(h.history['val_loss'])\n","axs[2].legend(['train', 'validation'], loc='upper right', fontsize = 20)\n","axs[2].set_title('model loss',x=0.5, y=1, fontsize=40)\n","axs[2].tick_params(axis='both', which='major', labelsize=20)\n","plt.savefig(f'/content/drive/MyDrive/brain_mri_segmentation/weights/fig/plot.pdf', bbox_inches='tight', pad_inches=0)\n"],"metadata":{"id":"7hV-sfvPsPTd","executionInfo":{"status":"aborted","timestamp":1654626798842,"user_tz":-420,"elapsed":66,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"NuissPQR_YbJ","executionInfo":{"status":"aborted","timestamp":1654626798843,"user_tz":-420,"elapsed":67,"user":{"displayName":"Dung Nguyen","userId":"14144089517691048599"}}},"execution_count":null,"outputs":[]}]}